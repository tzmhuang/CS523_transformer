{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsIEGsUevk7w",
        "outputId": "3c8ae3e1-0a63-4973-e578-5e218d64973c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openkiwi in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: hydra-core<0.12.0,>=0.11.3 in /usr/local/lib/python3.7/dist-packages (from openkiwi) (0.11.3)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.29 in /usr/local/lib/python3.7/dist-packages (from openkiwi) (4.64.0)\n",
            "Requirement already satisfied: scipy<2.0,>=1.2 in /usr/local/lib/python3.7/dist-packages (from openkiwi) (1.4.1)\n",
            "Requirement already satisfied: docopt<0.7.0,>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from openkiwi) (0.6.2)\n",
            "Requirement already satisfied: pydantic<2.0,>=1.5 in /usr/local/lib/python3.7/dist-packages (from openkiwi) (1.9.0)\n",
            "Requirement already satisfied: pyyaml<6.0.0,>=5.1.2 in /usr/local/lib/python3.7/dist-packages (from openkiwi) (5.4.1)\n",
            "Requirement already satisfied: pytorch-nlp<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from openkiwi) (0.5.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18 in /usr/local/lib/python3.7/dist-packages (from openkiwi) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions<4.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from openkiwi) (3.10.0.2)\n",
            "Collecting torch<1.7.0,>=1.4.0\n",
            "  Using cached torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
            "Requirement already satisfied: pytorch-lightning<0.9.0,>=0.8.4 in /usr/local/lib/python3.7/dist-packages (from openkiwi) (0.8.5)\n",
            "Requirement already satisfied: transformers<4.0.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from openkiwi) (3.5.1)\n",
            "Requirement already satisfied: more-itertools<9.0.0,>=8.0.0 in /usr/local/lib/python3.7/dist-packages (from openkiwi) (8.12.0)\n",
            "Requirement already satisfied: omegaconf<2.0.0,>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from openkiwi) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.0.0,>=1.4.1->openkiwi) (1.15.0)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (2.8.0)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (0.18.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (0.4.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (1.35.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (3.3.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (1.44.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning<0.9.0,>=0.8.4->openkiwi) (3.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.0.2->openkiwi) (21.3)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.0.2->openkiwi) (0.9.3)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.0.2->openkiwi) (0.1.91)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.0.2->openkiwi) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.0.2->openkiwi) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<4.0.0,>=3.0.2->openkiwi) (0.0.49)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<4.0.0,>=3.0.2->openkiwi) (3.0.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.0.0,>=3.0.2->openkiwi) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<4.0.0,>=3.0.2->openkiwi) (7.1.2)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.7.0\n",
            "    Uninstalling torch-1.7.0:\n",
            "      Successfully uninstalled torch-1.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.6.0\n",
            "Requirement already satisfied: torchtext==0.8.0 in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Collecting torch==1.7.0\n",
            "  Using cached torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n",
            "Requirement already satisfied: pytorch-lightning==0.8.5 in /usr/local/lib/python3.7/dist-packages (0.8.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.8.0) (4.64.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.18.2)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (0.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.0) (3.10.0.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==0.8.5) (5.4.1)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==0.8.5) (2.8.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.8.5) (1.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.8.5) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.8.5) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.8.5) (1.0.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.8.5) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.8.5) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.8.5) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.8.5) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.8.5) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.8.5) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=1.14->pytorch-lightning==0.8.5) (3.3.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=1.14->pytorch-lightning==0.8.5) (1.15.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.8.5) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.8.5) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.8.5) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning==0.8.5) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning==0.8.5) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=1.14->pytorch-lightning==0.8.5) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=1.14->pytorch-lightning==0.8.5) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.8.0) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->pytorch-lightning==0.8.5) (3.2.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.6.0\n",
            "    Uninstalling torch-1.6.0:\n",
            "      Successfully uninstalled torch-1.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.12.0+cu113 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\n",
            "openkiwi 2.1.0 requires torch<1.7.0,>=1.4.0, but you have torch 1.7.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openkiwi\n",
        "!pip install torchtext==0.8.0 torch==1.7.0 pytorch-lightning==0.8.5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "SNXq4ujj2PpA"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel\n",
        "bert = BertModel.from_pretrained('bert-base-multilingual-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZwvZMw58USN",
        "outputId": "1ab9776e-b080-4624-e549-abb229e5869b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[  101, 10747,   119,   102,     0,     0,     0],\n",
            "        [  101, 10747,   119,   102,     0,     0,     0],\n",
            "        [  101, 10747, 30832, 15953, 10238,   119,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1]])}\n",
            "torch.Size([3, 768])\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "model_name = \"bert-base-multilingual-cased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "bert = BertModel.from_pretrained(model_name)\n",
        "\n",
        "batch_sentence = ['This.', 'This.', 'Thissentecne.']\n",
        "\n",
        "input_enc = tokenizer(batch_sentence, padding=True, truncation=True, return_tensors='pt')\n",
        "print(input_enc)\n",
        "\n",
        "output = bert(**input_enc)\n",
        "last_hidden_state = output[0]\n",
        "feature = last_hidden_state.mean(dim=1)\n",
        "print(feature.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVyPzHd19XrN",
        "outputId": "445a9f81-245a-499e-da3c-99a5aff39648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 7, 768])\n"
          ]
        }
      ],
      "source": [
        "print(output[0].shape) ## only use output[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5Zhvnok9uyr",
        "outputId": "3c10591c-0411-463a-ae59-33605ec5a4fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3251, -0.1474,  0.5211,  ..., -0.2515,  0.1768,  0.1284],\n",
            "        [ 0.0993, -0.1326,  0.9122,  ..., -0.2344,  0.2030,  0.1319],\n",
            "        [ 0.3425, -0.1206,  0.7036,  ..., -0.2463, -0.1433,  0.0766],\n",
            "        ...,\n",
            "        [ 0.1638, -0.0412,  0.9428,  ..., -0.3129,  0.1093,  0.0201],\n",
            "        [ 0.3387, -0.0936,  0.8877,  ..., -0.3077,  0.0774,  0.1036],\n",
            "        [ 0.3463, -0.1507,  0.7943,  ..., -0.2378,  0.1089,  0.1300]],\n",
            "       grad_fn=<SelectBackward>)\n"
          ]
        }
      ],
      "source": [
        "print(output[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cndaYwiummiw",
        "outputId": "2011c8be-c86f-4300-b32b-fbf3e5ed1960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bX0W61hwjlKL"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from transformers.optimization import AdamW\n",
        "from torch import optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1ljnfqm1iHb",
        "outputId": "ced08e51-9af0-43f4-9e6d-8a8d6c91093a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eh1Cpo9zgw5m"
      },
      "outputs": [],
      "source": [
        "def read_annotated_file(path, index=\"index\"):\n",
        "    indices = []\n",
        "    originals = []\n",
        "    translations = []\n",
        "    z_means = []\n",
        "    with open(path, mode=\"r\", encoding=\"utf-8-sig\") as csvfile:\n",
        "        reader = csv.DictReader(csvfile, delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n",
        "        for row in reader:\n",
        "            indices.append(row[index])\n",
        "            originals.append(row[\"original\"])\n",
        "            translations.append(row[\"translation\"])\n",
        "            z_means.append(float(row[\"z_mean\"]))\n",
        "\n",
        "    return pd.DataFrame(\n",
        "        {'index': indices,\n",
        "         'original': originals,\n",
        "         'translation': translations,\n",
        "         'z_mean': z_means\n",
        "         })\n",
        "\n",
        "def read_test_file(path, index=\"index\"):\n",
        "    indices = []\n",
        "    originals = []\n",
        "    translations = []\n",
        "    with open(path, mode=\"r\", encoding=\"utf-8-sig\") as csvfile:\n",
        "        reader = csv.DictReader(csvfile, delimiter=\"\\t\", quoting=csv.QUOTE_NONE)\n",
        "        for row in reader:\n",
        "            indices.append(row[index])\n",
        "            originals.append(row[\"original\"])\n",
        "            translations.append(row[\"translation\"])\n",
        "\n",
        "    return pd.DataFrame(\n",
        "        {'index': indices,\n",
        "         'original': originals,\n",
        "         'translation': translations,\n",
        "         })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "60aHA4MYfWxm"
      },
      "outputs": [],
      "source": [
        "TRAIN_FILE = \"/content/drive/MyDrive/en-de/train.ende.df.short.tsv\"\n",
        "DEV_FILE = \"/content/drive/MyDrive/en-de/dev.ende.df.short.tsv\"\n",
        "TEST_FILE = \"/content/drive/MyDrive/en-de/test20.ende.df.short.tsv\"\n",
        "train_data = read_annotated_file(TRAIN_FILE)\n",
        "dev_data = read_annotated_file(DEV_FILE)\n",
        "test_data = read_annotated_file(TEST_FILE)\n",
        "train_data = train_data[['original', 'translation', 'z_mean']]\n",
        "dev_data = dev_data[['original', 'translation', 'z_mean']]\n",
        "test_data = test_data[['original', 'translation', 'z_mean']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "g_U7x_jD7mC6"
      },
      "outputs": [],
      "source": [
        "class QEDataset(Dataset):\n",
        "    def __init__(self, myDataset):\n",
        "        self.dataset = myDataset\n",
        "        self.original = myDataset['original']\n",
        "        self.translation = myDataset['translation']\n",
        "        self.z_mean = myDataset['z_mean']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (self.original[index], self.translation[index], self.z_mean[index])\n",
        "\n",
        "\n",
        "class QEDataLoader(DataLoader):\n",
        "    def __init__(self, data_dir, batch_size):\n",
        "        dataset = QEDataset(data_dir)\n",
        "        super().__init__(dataset, batch_size=batch_size, collate_fn=self.collate_fn)\n",
        "        return\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        src_batch, trg_batch, score_batch = [], [], []\n",
        "        for src_sample, trg_sample, score_sample in batch:\n",
        "            src_batch.append(src_sample)\n",
        "            trg_batch.append(trg_sample)\n",
        "            score_batch.append(score_sample)\n",
        "        # src_batch = pad_sequence(\n",
        "        #     src_batch, padding_value=PAD_IDX, batch_first=True)\n",
        "        # trg_batch = pad_sequence(\n",
        "        #     trg_batch, padding_value=PAD_IDX, batch_first=True)\n",
        "        # score_batch = torch.tensor(score_batch).unsqueeze(-1)\n",
        "        return src_batch, trg_batch, score_batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "QaXgc2GqlUVM"
      },
      "outputs": [],
      "source": [
        "class Mlp(nn.Module):\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
        "        super().__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
        "        self.act = act_layer()\n",
        "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
        "        self.drop = nn.Dropout(drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.drop(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop(x)\n",
        "        return x\n",
        "\n",
        "class BertQE(nn.Module):\n",
        "    def __init__(self, hidden_dim=768, model_name=\"bert-base-multilingual-cased\"):\n",
        "        super().__init__()\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "        self.bert = BertModel.from_pretrained(model_name)\n",
        "        self.linear1 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.output = Mlp(hidden_dim*2, hidden_dim*2, 1, drop=0.1)\n",
        "\n",
        "    @staticmethod\n",
        "    def merge_input(source, target):\n",
        "        merge_sentence = source + target\n",
        "        return merge_sentence\n",
        "    \n",
        "    def forward(self, batch_sentence):\n",
        "        merge_sentence = self.merge_input(**batch_sentence)\n",
        "        input_enc = self.tokenizer(merge_sentence, padding=True, truncation=True, return_tensors='pt')\n",
        "        input_enc = input_enc.to(device)\n",
        "        output = self.bert(**input_enc)\n",
        "\n",
        "        last_hidden_state = output[0] # bs*2 L C\n",
        "        batch_size = last_hidden_state.shape[0] // 2\n",
        "        source_hidden_state, target_hidden_state = torch.split(last_hidden_state, batch_size, dim=0)\n",
        "        source_feature = self.linear1(source_hidden_state).mean(dim=1, keepdim=True) # bs L C -> bs 1 C\n",
        "        target_feature = self.linear1(target_hidden_state).mean(dim=1, keepdim=True) # bs L C -> bs 1 C\n",
        "        feature = torch.cat([source_feature, target_feature], dim=-1) # bs 1 2C\n",
        "        output = self.output(feature).reshape(-1) # bs 1 1\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VJ4x63bLCGyu"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bzFZUkPB2L2"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = QEDataLoader(train_data, batch_size=batch_size)\n",
        "dev_dataloader = QEDataLoader(dev_data, batch_size=batch_size)\n",
        "test_dataloader = QEDataLoader(test_data, batch_size=batch_size)\n",
        "loss_fn = nn.MSELoss()\n",
        "model = BertQE().to(device)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "DqFLIoA0DvL9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiEipsQHnynE",
        "outputId": "e5808dfa-211f-4d96-aacf-0c294c0eb686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss in the 100 batch is 0.7583077780902385\n",
            "Loss in the 200 batch is 0.6897998540848493\n",
            "Loss in the 300 batch is 0.7195095178236564\n",
            "Loss in the 400 batch is 0.6867069607414306\n",
            "Loss in the 500 batch is 0.7018794027864933\n",
            "Loss in the 600 batch is 0.6966756123304367\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "epoc = 20\n",
        "epoch_loss = 0.0\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "def train():\n",
        "    for i in range(epoc):\n",
        "      for batch, (src_batch, trg_batch, score_batch) in enumerate(train_dataloader):\n",
        "        batch_sentence = dict()\n",
        "        batch_sentence['source'] = src_batch\n",
        "        batch_sentence['target'] = trg_batch\n",
        "        output = model(batch_sentence)\n",
        "        # print(output)\n",
        "        # print(type(output))\n",
        "        # print(type(score_batch))\n",
        "        score_batch = torch.Tensor(score_batch)\n",
        "        score_batch = score_batch.to(device)\n",
        "        loss = loss_fn(output, score_batch)\n",
        "        global count\n",
        "        global epoch_loss\n",
        "        epoch_loss = epoch_loss + loss.item()\n",
        "        count = count + 1\n",
        "        if count % 100 == 0:\n",
        "          print(\"Loss in the \" + str(count) + \" batch is \" + str(epoch_loss / count))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jxffl2UqlUjL"
      },
      "outputs": [],
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    test(test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-OiSw3aFwqN"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6V6B02Ec1l5b"
      },
      "outputs": [],
      "source": [
        "from kiwi.lib.pretrain import pretrain_from_file\n",
        "import kiwi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LO1YiZu8kqH2"
      },
      "outputs": [],
      "source": [
        "path = \"MyDrive/Datasets/shared\"\n",
        "model_path = path + \"/estimator_en_de.torch\"\n",
        "data_path = \"/content/drive/MyDrive/Datasets/shared/en-de/train.ende.df.short.tsv\"\n",
        "en_de_df = pd.read_csv(data_path, sep='\\t')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28OU5dVKtw69"
      },
      "outputs": [],
      "source": [
        "ori = en_de_df.get(\"original\").to_numpy()\n",
        "trans = en_de_df.get(\"translation\").to_numpy()\n",
        "tar_mean = en_de_df.get(\"mean\").to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waqF5ZIt_WI_"
      },
      "outputs": [],
      "source": [
        "def save_config(yaml_config, name):\n",
        "    \"\"\" Writes yaml config to file\"\"\"\n",
        "    with open(name, 'w') as outfile:\n",
        "        yaml.dump(yaml_config, outfile, default_flow_style=False)\n",
        "save_config(\"/content/drive/MyDrive/Datasets/shared/nuqe.yaml\",'nuqe_config.yml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyn6Sq1o_l1A"
      },
      "outputs": [],
      "source": [
        "config = '/content/drive/MyDrive/Datasets/shared/nuqe.yaml'\n",
        "run_info = kiwi.lib.train.train_from_file(config)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Bert_QE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}